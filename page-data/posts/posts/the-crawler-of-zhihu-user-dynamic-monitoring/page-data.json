{"componentChunkName":"component---src-templates-post-tsx","path":"/posts/posts/the-crawler-of-zhihu-user-dynamic-monitoring/","result":{"data":{"markdownRemark":{"html":"<blockquote>\n<p>根据极客学院的Python爬虫教程写的一个单线程简易爬虫。可以监控知乎用户动态，当有新动态时发送邮件通知。</p>\n</blockquote>\n<h4>步骤</h4>\n<ul>\n<li>根据要关注的知乎用户的主页URL，使用requests模块获取整个用户主页的html。</li>\n<li>根据用户主页及其html代码，定位所需要的最新动态的位置。</li>\n<li>使用正则表达式比配到需要的数据。</li>\n<li>拼接数据，判断是否已经保持在文件中，即判断是否为新动态。</li>\n<li>若是新动态，使用python的smtplib模块发送收件到设置的邮箱中并保存到本地文件，否则略过。</li>\n</ul>\n<!--more-->\n<h4>模块</h4>\n<p><code>os</code>\n<code>time</code>\n<code>re</code>\n<code>sys</code>\n<code>MIMEText</code>\n<code>requests</code>\n<code>smtplib</code></p>\n<!--more-->\n<h4>zhihu类：获取与匹配，保持内容</h4>\n<pre><code>class zhihu(object):\n\n    def __init__(self):\n        # 设置关注的知乎用户\n        self.url = \"http://www.zhihu.com/people/xxxx\"\n        # 设置request header\n        self.header = {\n            'Host' : 'www.zhihu.com',\n            'Connection' : 'Keep-Alive',\n            'Accept' : 'text/html, application/xhtml+xml, image/jxr, */*',\n            'User-Agent' : 'Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.80 Safari/537.36',\n            'Referer': self.url\n        }\n        # 设置登录的Cookie\n        self.cookie = {\n            'Cookie' : ''\n        }\n\n    # 获取知乎用户的主页HTML\n    def getHTML(self):\n        html = requests.get(self.url, headers = self.header, cookies = self.cookie).content\n        return html\n\n    # 获取最新动态\n    def getContent(self, html):\n        self.name = re.findall('&#x3C;span class=\"name\">(.*?)&#x3C;/span>', html, re.S)[0]\n        content = re.findall('&#x3C;div class=\"zm-profile-section-main zm-profile-section-activity-main zm-profile-activity-page-item-main\">(.*?)&#x3C;/div>', html, re.S)\n        return content\n\n    # 获取每一条最新动态\n    def getText(self, contents):\n        data = {}\n        data['href'] = re.findall('href=\"/question/(.*?)\"', contents, re.S)\n        data['question'] = re.findall('&#x3C;a class=\"question_link\" .*?\">(.*?)&#x3C;/a>', contents, re.S)\n        restr = '\">'+ self.name +'&#x3C;/a>(.*?)\\n\\n&#x3C;a'\n        data['action'] = re.findall(restr, contents, re.S)\n        text = self.name + data['action'] + ': ' +  data['question'] + ' http://www.zhihu.com/question/'+ data['href'] + '\\n'\n        return text\n\n    # 保存到文本\n    def toSave(self, text):\n        f = open('zhihu.txt', 'a')\n        f.write(text)\n        f.close()\n\n    # 检查动态是否已记录\n    def toCheck(self, text):\n        f = open('zhihu.txt', 'r')\n        existzhihu = f.readlines()\n        if text in existzhihu:\n            return False\n        else:\n            return True\n</code></pre>\n<h4>mail类：发送邮件</h4>\n<pre><code>class mail(object):\n\n    def __init__(self):\n        #邮件服务器地址，需要打开smtp\n        self.mail_host = \"smtp.xxx.cn\"\n        #邮件账号\n        self.mail_user = \"\"\n        #邮箱密码\n        self.mail_pass = \"\"\n        #邮箱后缀\n        self.mail_postfix = \"xxx.com\"\n\n    def sendMail(self, toList, sub, content):\n        #发信人\n        me = \"zhihu spider\" + \"&#x3C;\" + self.mail_user + \"@\" + self.mail_postfix + \">\"\n        msg = MIMEText(content, _subtype='plain', _charset='utf-8')\n         #邮件标题\n        msg['Subject'] = sub\n        #邮件发送人\n        msg['From'] = me\n        #邮件收件人\n        msg['To'] = \";\".join(toList)\n        try:\n            server = smtplib.SMTP()\n            #连接服务器\n            server.connect(self.mail_host)\n            #登录邮箱\n            server.login(self.mail_user,self.mail_pass)\n            #发送邮件\n            server.sendmail(me, toList, msg.as_string())\n            server.close()\n            return True\n        except Exception, e:\n            print str(e)\n            return False\n</code></pre>\n<h4>运行</h4>\n<pre><code>if __name__ == '__main__':\n    # 设置收件人邮箱\n    mailToList = ['xxx@xxx.com']\n    zhihu = zhihu();\n    while True:\n        html = zhihu.getHTML()\n        content = zhihu.getContent(html)\n        # 若没有动态记录，爬取所有动态，并保存\n        if not os.path.exists('zhihu.txt'):\n            for contents in content:\n                text = zhihu.getText(contents)\n                zhihu.toSave(text)\n        else:\n            text = zhihu.getText(content[0])\n            print text\n            # 检查是否存在记录， 不存在则发送邮件，并保存到文件\n            if zhihu.toCheck(text):\n                if mail().sendMail(mailToList, \"知乎动态\", text):\n                    zhihu.toSave(text)\n                    print \"发生成功\"\n                else:\n                    print \"发送失败\"\n            else:\n                print \"pass\"\n            # 每隔2分钟运行一次，检查新动态\n            time.sleep(120)\n</code></pre>\n<h4>总结</h4>\n<p>这个简单的爬虫目前还没有办法同时关注很多用户，然后对ip也没有进行代理，爬取过于频繁的话可能会被封ip而爬取不到。</p>\n<p>在爬取知乎的过程中发现如果没有header,可能返回的html页面不是用户的主页。然后如果没有登录的话，看到的知乎用户的主页刷新缓慢。需要模拟登录后才能够实时刷新出新动态。</p>\n<p>同时使用的是re库正则匹配内容，在使用上不是很方便。但是对xpath又不是很熟，所以暂时使用正则取匹配。</p>\n<p>之前还有看到一个解析html内容的模块叫BeautifulSoup，准备去学习学习。然后打算下次使用pythopn的爬虫框架Scrapy来写更多功能的知乎爬虫。</p>","rawMarkdownBody":"\r\n> 根据极客学院的Python爬虫教程写的一个单线程简易爬虫。可以监控知乎用户动态，当有新动态时发送邮件通知。\r\n\r\n#### 步骤\r\n- 根据要关注的知乎用户的主页URL，使用requests模块获取整个用户主页的html。\r\n- 根据用户主页及其html代码，定位所需要的最新动态的位置。\r\n- 使用正则表达式比配到需要的数据。\r\n- 拼接数据，判断是否已经保持在文件中，即判断是否为新动态。\r\n- 若是新动态，使用python的smtplib模块发送收件到设置的邮箱中并保存到本地文件，否则略过。\r\n\r\n<!--more-->\r\n#### 模块\r\n`os`\r\n`time`\r\n`re`\r\n`sys`\r\n`MIMEText`\r\n`requests`\r\n`smtplib`\r\n<!--more-->\r\n\r\n#### zhihu类：获取与匹配，保持内容\r\n\r\n```\r\nclass zhihu(object):\r\n\r\n    def __init__(self):\r\n        # 设置关注的知乎用户\r\n        self.url = \"http://www.zhihu.com/people/xxxx\"\r\n        # 设置request header\r\n        self.header = {\r\n            'Host' : 'www.zhihu.com',\r\n            'Connection' : 'Keep-Alive',\r\n            'Accept' : 'text/html, application/xhtml+xml, image/jxr, */*',\r\n            'User-Agent' : 'Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.80 Safari/537.36',\r\n            'Referer': self.url\r\n        }\r\n        # 设置登录的Cookie\r\n        self.cookie = {\r\n            'Cookie' : ''\r\n        }\r\n\r\n    # 获取知乎用户的主页HTML\r\n    def getHTML(self):\r\n        html = requests.get(self.url, headers = self.header, cookies = self.cookie).content\r\n        return html\r\n\r\n    # 获取最新动态\r\n    def getContent(self, html):\r\n        self.name = re.findall('<span class=\"name\">(.*?)</span>', html, re.S)[0]\r\n        content = re.findall('<div class=\"zm-profile-section-main zm-profile-section-activity-main zm-profile-activity-page-item-main\">(.*?)</div>', html, re.S)\r\n        return content\r\n\r\n    # 获取每一条最新动态\r\n    def getText(self, contents):\r\n        data = {}\r\n        data['href'] = re.findall('href=\"/question/(.*?)\"', contents, re.S)\r\n        data['question'] = re.findall('<a class=\"question_link\" .*?\">(.*?)</a>', contents, re.S)\r\n        restr = '\">'+ self.name +'</a>(.*?)\\n\\n<a'\r\n        data['action'] = re.findall(restr, contents, re.S)\r\n        text = self.name + data['action'] + ': ' +  data['question'] + ' http://www.zhihu.com/question/'+ data['href'] + '\\n'\r\n        return text\r\n\r\n    # 保存到文本\r\n    def toSave(self, text):\r\n        f = open('zhihu.txt', 'a')\r\n        f.write(text)\r\n        f.close()\r\n\r\n    # 检查动态是否已记录\r\n    def toCheck(self, text):\r\n        f = open('zhihu.txt', 'r')\r\n        existzhihu = f.readlines()\r\n        if text in existzhihu:\r\n            return False\r\n        else:\r\n            return True\r\n```\r\n\r\n#### mail类：发送邮件\r\n\r\n```\r\nclass mail(object):\r\n\r\n    def __init__(self):\r\n        #邮件服务器地址，需要打开smtp\r\n        self.mail_host = \"smtp.xxx.cn\"\r\n        #邮件账号\r\n        self.mail_user = \"\"\r\n        #邮箱密码\r\n        self.mail_pass = \"\"\r\n        #邮箱后缀\r\n        self.mail_postfix = \"xxx.com\"\r\n\r\n    def sendMail(self, toList, sub, content):\r\n        #发信人\r\n        me = \"zhihu spider\" + \"<\" + self.mail_user + \"@\" + self.mail_postfix + \">\"\r\n        msg = MIMEText(content, _subtype='plain', _charset='utf-8')\r\n         #邮件标题\r\n        msg['Subject'] = sub\r\n        #邮件发送人\r\n        msg['From'] = me\r\n        #邮件收件人\r\n        msg['To'] = \";\".join(toList)\r\n        try:\r\n            server = smtplib.SMTP()\r\n            #连接服务器\r\n            server.connect(self.mail_host)\r\n            #登录邮箱\r\n            server.login(self.mail_user,self.mail_pass)\r\n            #发送邮件\r\n            server.sendmail(me, toList, msg.as_string())\r\n            server.close()\r\n            return True\r\n        except Exception, e:\r\n            print str(e)\r\n            return False\r\n\r\n```\r\n\r\n#### 运行\r\n\r\n```\r\nif __name__ == '__main__':\r\n    # 设置收件人邮箱\r\n    mailToList = ['xxx@xxx.com']\r\n    zhihu = zhihu();\r\n    while True:\r\n        html = zhihu.getHTML()\r\n        content = zhihu.getContent(html)\r\n        # 若没有动态记录，爬取所有动态，并保存\r\n        if not os.path.exists('zhihu.txt'):\r\n            for contents in content:\r\n                text = zhihu.getText(contents)\r\n                zhihu.toSave(text)\r\n        else:\r\n            text = zhihu.getText(content[0])\r\n            print text\r\n            # 检查是否存在记录， 不存在则发送邮件，并保存到文件\r\n            if zhihu.toCheck(text):\r\n                if mail().sendMail(mailToList, \"知乎动态\", text):\r\n                    zhihu.toSave(text)\r\n                    print \"发生成功\"\r\n                else:\r\n                    print \"发送失败\"\r\n            else:\r\n                print \"pass\"\r\n            # 每隔2分钟运行一次，检查新动态\r\n            time.sleep(120)\r\n```\r\n\r\n#### 总结\r\n这个简单的爬虫目前还没有办法同时关注很多用户，然后对ip也没有进行代理，爬取过于频繁的话可能会被封ip而爬取不到。\r\n\r\n在爬取知乎的过程中发现如果没有header,可能返回的html页面不是用户的主页。然后如果没有登录的话，看到的知乎用户的主页刷新缓慢。需要模拟登录后才能够实时刷新出新动态。\r\n\r\n同时使用的是re库正则匹配内容，在使用上不是很方便。但是对xpath又不是很熟，所以暂时使用正则取匹配。\r\n\r\n之前还有看到一个解析html内容的模块叫BeautifulSoup，准备去学习学习。然后打算下次使用pythopn的爬虫框架Scrapy来写更多功能的知乎爬虫。\r\n","frontmatter":{"title":"知乎用户动态监控爬虫","date":"2015年11月25日","tags":["Python","知乎"]}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/posts/the-crawler-of-zhihu-user-dynamic-monitoring/"}}}